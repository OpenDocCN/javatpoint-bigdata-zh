# PySpark 教程

> 原文:[https://www.javatpoint.com/pyspark](https://www.javatpoint.com/pyspark)

![What is PySpark](../Images/f50c2516c59c4a4243e7bb961921a082.png)

PySpark 教程提供了 Spark 的基本概念和高级概念。我们的 PySpark 教程是为初学者和专业人士设计的。

PySpark 是使用 Spark 的 Python API。Spark 是一个开源的集群计算系统，用于大数据解决方案。为快速计算而设计的是闪电般的技术。

我们的 PySpark 教程包括所有与 PySpark 简介、PySpark 安装、PySpark 架构、PySpark 数据框架、PySpark Mlib、PySpark RDD、PySpark 过滤器等相关的主题。

## 什么是 PySpark？

PySpark 是一个 Python API，用 Apache Spark 支持 Python。PySpark 提供 **Py4j 库，**借助这个库，Python 可以很容易地与 Apache Spark 集成。当 PySpark 需要处理大量数据集或分析它们时，它起着至关重要的作用。PySpark 的这一特性使其成为数据工程师中要求非常高的工具。

## PySpark 的主要特性

PySpark 有以下各种特性:

![What is PySpark](../Images/f978e8820d2dd3896914b6711cd6b1a3.png)

*   **实时计算**

PySpark 提供了对大量数据的实时计算，因为它专注于内存中的处理。它显示了低延迟。

*   **支持多语言**

PySpark 框架适用于各种编程语言，如 **Scala、Java、Python 和 R.** ，其兼容性使其成为处理大型数据集的首选框架。

*   **缓存和磁盘恒定性**

PySpark 框架提供了强大的缓存和良好的磁盘恒定性。

*   **快速处理**

PySpark 让我们实现了很高的数据处理速度，在内存上大约快 100 倍，在磁盘上快 10 倍。

*   **与 RDD 配合良好**

Python 编程语言是动态类型的，这在使用 RDD 时很有帮助。我们将在后续教程中了解更多关于 RDD 使用 Python 的信息。

## 什么是 Apache Spark？

Apache Spark 是 Apache 软件基金会推出的**开源分布式集群计算框架**。它是大数据分析、处理和计算的通用引擎。它专为高速、易用性而打造，提供简单性、流分析，几乎可以在任何地方运行。它可以实时分析数据。它提供了对大数据的快速计算。

快速的**计算意味着它比以前处理大数据的方法(如 **MapReduce)更快。**Apache Spark 的主要特点是其**内存集群**计算，可提高应用程序的处理速度。**

 **它可以用于多种用途，如运行分布式 SQL、创建数据管道、将数据引入数据库、运行机器学习算法、处理图形或数据流等。

## 为什么是 PySpark？

大量数据是离线和在线生成的。这些数据包含了隐藏模式、未知修正、市场趋势、客户偏好等有用的商业信息。有必要从原始数据中提取有价值的信息。

![What is PySpark?](../Images/104b7823f400342b87bbe70b588643a9.png)

我们需要更高效的工具来对大数据执行不同类型的操作。有各种工具可以在庞大的数据集上执行多项任务，但这些工具不再那么吸引人了。破解大数据并从中获益，需要一些可扩展、灵活的工具。

## Scala 和 PySpark 的区别

Apache Spark 正式用 Scala 编程语言编写。让我们来看看 Python 和 Scala 的本质区别。

| Sr | 计算机编程语言 | 斯卡拉 |
| **1。** | Python 是一种解释的动态编程语言。 | Scala 是一种静态类型的语言。 |
| **2。** | Python 是面向对象的编程语言。 | 在 Scala 中，我们需要指定变量和对象的类型。 |
| **3。** | Python 易于学习和使用。 | Scala 比 Python 稍微难学一点。 |
| **4。** | Python 比 Scala 慢，因为它是一种解释语言。 | Scala 比 Python 快 10 倍。 |
| **5。** | Python 是一种开源语言，有一个庞大的社区可以让它变得更好。 | Scala 也有一个优秀的社区，但不如 Python。 |
| **6。** | Python 包含大量的库，是数据科学和机器学习的完美工具。 | Scala 没有这样的工具。 |

![What is PySpark](../Images/67bc2b5ea476dad75c9db7c025d091fd.png)

帮助处理大数据的最神奇的工具之一是 **Apache Spark。**众所周知，Python 是数据科学家、数据分析和各个领域中使用最广泛的编程语言之一。由于其简单性和交互式界面，它被数据科学家信任使用 Python 对大数据执行数据分析、机器学习和许多其他任务。

因此，Python 和 Spark 的结合对于大数据世界来说是非常有效的。这就是为什么 Apache Spark 社区想出了一个名为 **PySpark** 的工具，这是一个针对 Apache Spark 的 Python API。

## PySpark 的实际使用

数据是每个行业必不可少的东西。大多数行业从事大数据工作，并雇佣分析师从原始数据中提取有用的信息。让我们来看看 PySpark 对几个行业的影响。

**1。娱乐行业**

娱乐业是向在线流媒体发展的最大行业之一。受欢迎的在线娱乐平台**网飞**使用 Apache spark 对其客户的个性化在线电影或网络系列进行实时处理。它处理大约。服务器端应用程序每天流传输 4500 亿个事件。

**2。商业领域**

商业部门也使用 Apache Spark 的实时处理系统。银行和其他金融领域正在使用 Spark 检索客户的社交媒体档案并进行分析，以获得有用的见解，从而有助于做出正确的决策。

提取的信息用于信用风险评估、定向广告和客户细分。

Spark 在**欺诈检测**中起着重要作用，广泛应用于机器学习任务。

**3。医疗保健**

Apache Spark 用于分析患者记录以及以前的医疗报告数据，以确定哪个患者在出院后可能会面临健康问题。

**4。贸易和电子商务**

Flipkart、亚马逊等领先的电子商务网站使用 Apache Spark 进行定向广告。其他网站如**阿里巴巴**提供有针对性的优惠，增强客户体验，优化整体表现。

**5。旅游行业**

旅游业广泛使用 Apache Spark，通过比较数百个旅游网站，为数百万旅行者提供建议。

在本教程中，我们已经了解了 PySpark 简介，我们将在后续教程中了解更多关于 PySpark 的内容。

## 先决条件

在学习 PySpark 之前，您必须对编程语言和框架有一个基本的了解。如果你对 Apache Spark、Hadoop、Scala 编程语言、Hadoop 分布式文件系统(HDFS)和 Python 有很好的了解，那将是非常有益的。

## 观众

我们的 PySpark 教程旨在帮助初学者和专业人士。

## 问题

我们向您保证，您不会发现这个 PySpark 教程有任何问题。但是，如果有任何错误，请在联系表格中发布问题。

* * ***