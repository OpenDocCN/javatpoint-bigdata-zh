# HDFS 是什么

> 原文:[https://www.javatpoint.com/hdfs](https://www.javatpoint.com/hdfs)

Hadoop 附带了一个名为 HDFS 的分布式文件系统。在 HDFS，数据分布在几台机器上并被复制，以确保它们的故障持久性和并行应用的高可用性。

它使用商品硬件，因此具有成本效益。它涉及块、数据节点和节点名的概念。

## 在哪里使用 HDFS

*   **非常大的文件:**文件应该是百兆字节、千兆字节或更多。
*   **流数据访问:**读取整个数据集的时间比读取第一个数据集的延迟更重要。HDFS 建立在一次写入多次读取的模式上。
*   **商品硬件:**在低成本硬件上工作。

## 哪里不用 HDFS

*   **低延迟数据访问:**需要非常少的时间来访问第一个数据的应用程序不应该使用 HDFS，因为它重视整个数据，而不是获取第一条记录的时间。
*   **大量小文件:**名称节点包含内存中文件的元数据，如果文件很小，那么名称节点的内存需要大量内存，这是不可行的。
*   **多次写入:**当我们必须多次写入时，不应该使用它。

## HDFS 概念

1.  **块:**块是它可以读取或写入的最小数据量。默认情况下，HDFS 数据块为 128 MB，这是可配置的。HDFS 的文件被分成块大小的块，作为独立的单元存储。与文件系统不同，如果文件在 HDFS 小于数据块大小，那么它不会占用整个数据块？的大小，即存储在 HDFS 的 5 MB 文件的块大小为 128 MB，仅占用 5MB 的空间。HDFS 块的大小很大，只是为了最小化寻道成本。
2.  **名称节点:** HDFS 以主从模式工作，其中名称节点充当主节点。名称节点是 HDFS 的控制器和管理器，因为它知道 HDFS 所有文件的状态和元数据；元数据信息是文件许可、每个块的名称和位置。元数据很小，所以它存储在名称节点的内存中，允许更快地访问数据。此外，HDFS 群集由多个客户端同时访问，因此所有这些信息都由一台机器处理。文件系统操作，如打开、关闭、重命名等。被它执行。
3.  **数据节点:**当被告知时，它们存储和检索块；按客户端或名称节点。他们定期向名称节点报告，并列出他们正在存储的数据块。作为商用硬件的数据节点还执行数据块创建、删除和复制的工作，如名称节点所述。

HDFS 数据节点和名称节点图像:

![HDFS DataNode NameNode](../Images/f4071d2e0af0ad4ac9778b85029ff08a.png)

HDFS 阅读图像:

![HDFS Read](../Images/44a0bd1b66bbdb9e7c03ff1dde259613.png)

HDFS 写图像:

![HDFS Write](../Images/aff4251fa16149d95fe934b5f254fbf6.png)

由于所有元数据都存储在名称节点中，因此非常重要。如果失败，文件系统将无法使用，因为无法知道如何从数据节点中的数据块重建文件。为了克服这一点，出现了次名节点的概念。

**辅助名称节点:**它是一个单独的物理机器，充当名称节点的助手。它执行定期检查点。它与名称节点通信，并拍摄元数据的快照，这有助于最大限度地减少停机时间和数据丢失。

## 从 HDFS 开始

HDFS 应该首先格式化，然后在分布式模式下启动。命令如下。

格式化 **$ hadoop 名称节点-格式化**

启动 **$ start-dfs.sh**

## HDFS 基本文件操作

1.  将数据从本地文件系统放入 HDFS

    *   首先在 HDFS 创建一个文件夹，数据可以从本地文件系统放入其中。

    $ Hadoop fs-mkdir/用户/测试

    *   将文件“data.txt”从保存在本地文件夹/usr/home/Desktop 中的文件复制到 HDFS 文件夹/用户/测试

    $ Hadoop fs-copy from LocaL/usr/home/Desktop/data . txt/user/test

    *   显示 HDFS 文件夹的内容

    $ Hadoop fs-ls/用户/测试

2.  将数据从 HDFS 复制到本地文件系统

    *   $ Hadoop fs-CopyToLocal/user/test/data . txt/usr/bin/data _ copy . txt
3.  比较文件，看两者是否相同

    *   $ MD5/usr/bin/data _ copy . txt/usr/home/Desktop/data . txt

递归删除

*   hadoop fs -rmr

示例:

*   Hadoop fs-rmr/user/sleep/

## HDFS 其他命令

命令中使用了以下内容

“<path>”指任何文件或目录名。</path>

“<path>……”表示一个或多个文件名或目录名。</path>

“<file>”表示任何文件名。</file>

“<src>”和“<dest>”是定向操作中的路径名。</dest></src>

“<localsrc>”和“<localdest>”是如上所述的路径，但是在本地文件系统上</localdest></localsrc>

*   放<localsrc></localsrc>

将文件或目录从 localSrc 标识的本地文件系统复制到 DFS 中的 dest。

*   copyFromLocal<localsrc></localsrc>

与-put 相同

*   copyFromLocal<localsrc></localsrc>

与-put 相同

*   移动从本地<localsrc></localsrc>

将文件或目录从 localSrc 标识的本地文件系统复制到 HDFS 内的 dest，然后成功删除本地副本。

*   获取[-crc]<src><localdest></localdest></src>

将 src 标识的 HDFS 文件或目录复制到 localDest 标识的本地文件系统路径。

*   猫<filen-ame></filen-ame>

在 stdout 上显示文件名的内容。

*   moveToLocal<src><localdest></localdest></src>

工作方式类似于-get，但成功后会删除 HDFS 副本。

*   set rep[-r][-w]rep<path></path>

为通过复制路径标识的文件设置目标复制因子(随着时间的推移，实际复制因子将向目标移动)

*   触摸〔t0〕

在包含当前时间作为时间戳的路径下创建一个文件。如果路径中已经存在文件，则失败，除非该文件的大小已经是 0。

*   测试-[ezd]<path></path>

如果路径存在，则返回 1；长度为零；或者是目录或 0。

*   状态 [格式]<path></path>

打印路径信息。Format 是一个字符串，它接受以块(%b)、文件名(%n)、块大小(%o)、复制(%r)和修改日期(%y，%Y)为单位的文件大小。