# RDD 坚持

> 原文：<https://www.javatpoint.com/apache-spark-rdd-persistence>

Spark 通过跨操作将数据集保存在内存中，提供了一种处理数据集的便捷方法。在持久化 RDD 时，每个节点将它计算的任何分区存储在内存中。现在，我们还可以在该数据集的其他任务中重用它们。

我们可以使用 persist()或 cache()方法来标记要持久化的 RDD。Spark？的缓存是容错的。无论如何，如果 RDD 的分区丢失，它将使用最初创建它的转换自动重新计算。

可以使用不同的存储级别来存储持久化的关系数据库。通过传递一个 **StorageLevel** 对象(Scala、Java、Python)来持久化()来使用这些级别。但是，缓存()方法用于默认存储级别，即存储级别。仅内存。

以下是一组存储级别:

| 存储级别 | 描述 |
| 仅内存 | 它将 RDD 作为反序列化的 Java 对象存储在 JVM 中。这是默认级别。如果 RDD 不适合内存，一些分区将不会在每次需要时被缓存和重新计算。 |
| 内存和磁盘 | 它将 RDD 作为反序列化的 Java 对象存储在 JVM 中。如果 RDD 不适合内存，将不适合的分区存储在磁盘上，并在需要时从那里读取它们。 |
| 
(Java 和 Scala) | 它将 RDD 存储为序列化的 Java 对象(即每个分区一个字节数组)。这通常比反序列化的对象更节省空间。 |
| 内存和磁盘服务
(Java 和 Scala) | 它类似于 MEMORY_ONLY_SER，但是将不适合内存的分区溢出到磁盘，而不是重新计算它们。 |
| 仅磁盘 | 它只在磁盘上存储 RDD 分区。 |
| MEMORY_ONLY_2、MEMORY_AND_DISK_2 等。 | 它与上面的级别相同，但在两个群集节点上复制每个分区。 |
| 关闭堆(实验) | 它类似于 MEMORY_ONLY_SER，但将数据存储在堆外内存中。必须启用堆外内存。 |

* * *