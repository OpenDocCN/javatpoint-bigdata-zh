# 火花充电计数示例

> 原文：<https://www.javatpoint.com/apache-spark-char-count-example>

在火花字符计数示例中，我们发现每个字符在特定文件中存在的频率。这里，我们使用 Scala 语言来执行 Spark 操作。

## 执行火花充电计数示例的步骤

在这个例子中，我们找到并显示每个字符的出现次数。

*   在本地机器上创建一个文本文件，并在其中写入一些文本。

```

$ nano sparkdata.txt

```

![Spark Char Count Example](img/39c844d37dea5526c847ebd61e6f78ab.png)

*   检查 sparkdata.txt 文件中写入的文本。

```

$ cat sparkdata.txt

```

![Spark Char Count Example](img/3b7d200f2643ed6b55d3e14fb0f5f08e.png)

*   在 HDFS 创建一个目录，在那里保存文本文件。

```

$ hdfs dfs -mkdir /spark

```

*   将 HDFS 的 sparkdata.txt 文件上传到特定目录。

```

$ hdfs dfs -put /home/codegyani/sparkdata.txt /spark

```

![Spark Char Count Example](img/67bebb58465a13261a5ed4315acee16f.png)

*   现在，按照下面的命令在 Scala 模式下打开火花。

```

$ spark-shell

```

![Spark Char Count Example](img/3568ace5d1f3acb5a2f714415272ed94.png)

*   让我们使用以下命令创建一个 RDD。

```

scala> val data=sc.textFile("sparkdata.txt");

```

在这里，传递包含数据的任何文件名。

*   现在，我们可以使用以下命令读取生成的结果。

```

scala> data.collect;

```

![Spark Char Count Example](img/99aed8f823ecf0884fbddd2ae33b284c.png)

*   这里，我们使用以下命令将现有数据以单个单词的形式拆分。

```

scala> val splitdata = data.flatMap(line => line.split(""));

```

*   现在，我们可以使用以下命令读取生成的结果。

```

scala> splitdata.collect;

```

![Spark Char Count Example](img/a6d947359a261c50d2402bfa0a22b54c.png)

*   现在，执行地图操作。

```

scala> val mapdata = splitdata.map(word => (word,1));

```

这里，我们给每个单词赋值 1。

*   现在，我们可以使用以下命令读取生成的结果。

```

scala> mapdata.collect;

```

![Spark Char Count Example](img/97477696307a852f15d6b4fefba4d309.png)

*   现在，执行减少操作

```

scala> val reducedata = mapdata.reduceByKey(_+_);

```

这里，我们总结了生成的数据。

*   现在，我们可以使用以下命令读取生成的结果。

```

scala> reducedata.collect;

```

![Spark Char Count Example](img/15206768688ae406f66411ff9f64a89a.png)

在这里，我们得到了期望的输出。

* * *