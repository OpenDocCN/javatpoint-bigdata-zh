# Spark 优先函数

> 原文：<https://www.javatpoint.com/apache-spark-first-function>

在 Spark 中，First 函数总是返回数据集的第一个元素。它类似于采取(1)。

## 第一功能示例

在本例中，我们检索数据集的第一个元素。

*   要在 Scala 模式下打开 Spark，请执行以下命令。

```

$ spark-shell

```

![Spark First Function](img/d6bd3da0aa441ae8051421b8f0b592fd.png)

*   使用并行集合创建 RDD。

```

scala> val data = sc.parallelize(List(10,20,30,40,50))

```

*   现在，我们可以使用以下命令读取生成的结果。

```

scala> data.collect

```

![Spark First Function](img/1064e61897ae9801ca5c24b714f5a74a.png)

*   应用 first()函数检索数据集的第一个元素。

```

scala> val firstfunc = data.first()

```

![Spark First Function](img/ea6c30dd5695984e75344454ed3f8d27.png)

在这里，我们得到了期望的输出。

* * *